{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing of the necessary libraries\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First try with a basic fully connected one layer structure just to see data load and basic epoch run working\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Lambda(lambda x: (X_train / 255.0) - 0.5), input_shape=(160,320,3))\n",
    "model.add(Flatten(input_shape=(160,320,3)))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(norm(X_train), y_train, validation_split=0.2, shuffle=True, nb_epoch=7)\n",
    "\n",
    "#model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding right and left camera images to the dataset\n",
    "# Also added flipped version of whole images\n",
    "# As the third step only some part of the track added to whole data set. Then the data shuffled\n",
    "# 4th step - adding only part of a track data got things worse. Recorded full track data added.\n",
    "   \n",
    "def data_add(path, file_path):\n",
    "    augmented_images, augmented_measurements = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        first_line = f.readline()    # get rid of first row including string labels\n",
    "        for row in reader:\n",
    "            steering_center = float(row[3])\n",
    "\n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            correction = 0.2 # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            steering_right = steering_center - correction\n",
    "\n",
    "            # read in images from center, left and right cameras\n",
    "\n",
    "            img_center = cv2.imread(path + row[0].split('/')[-1])\n",
    "            ## process_image(np.asarray(Image.open(path + row[0])))\n",
    "            img_left = cv2.imread(path + row[1].split('/')[-1])\n",
    "            ## process_image(np.asarray(Image.open(path + row[1])))\n",
    "            img_right = cv2.imread(path + row[2].split('/')[-1])\n",
    "            ## process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "            # add images and angles to data set\n",
    "            augmented_images.append(img_center)\n",
    "            augmented_images.append(img_left)\n",
    "            augmented_images.append(img_right)\n",
    "\n",
    "            augmented_measurements.append(steering_center)\n",
    "            augmented_measurements.append(steering_left)\n",
    "            augmented_measurements.append(steering_right)\n",
    "\n",
    "            augmented_images.append(cv2.flip(img_center,1))\n",
    "            augmented_images.append(cv2.flip(img_left,1))\n",
    "            augmented_images.append(cv2.flip(img_right,1))\n",
    "\n",
    "            augmented_measurements.append(-steering_center)\n",
    "            augmented_measurements.append(-steering_left)\n",
    "            augmented_measurements.append(-steering_right)\n",
    "    return augmented_measurements, augmented_images\n",
    "\n",
    "aug_measurements, aug_images = [],[]\n",
    "\n",
    "aug_measurements, aug_images = data_add(\"data/IMG/\", 'data/driving_log.csv')\n",
    "\n",
    "# Adding personally created data - the necessity of this data explained in markup\n",
    "# personal_measurements, personal_images = data_add(\"data_celal/IMG/\", 'data_celal/driving_log.csv')\n",
    "personal_measurements, personal_images = data_add(\"data_full_path/IMG/\", 'data_full_path/driving_log.csv')\n",
    "\n",
    "aug_measurements.extend(personal_measurements)\n",
    "aug_images.extend(personal_images)\n",
    "\n",
    "X_train = np.array(aug_images)  \n",
    "y_train = np.array(aug_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test : to see number of pictures, to see numbers match\n",
    "print(len(X_train), len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to shuffle before training because i have added specific parts of the track to the data set. \n",
    "# This data added by me should be shuffled so validation data will be balanced. \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a modified VGGNet structure i found on the net.\n",
    "\n",
    "# Cropping layer added as it is not necessary to include top and bottom portions of the pictures\n",
    "# Also, network is too slow, it takes 8 hours to finish 20 epochs with using only test data given by Udacity\n",
    "\n",
    "# Also a lambda layer added for normalization. W/o this layer the values feed into simulator with drive.py became\n",
    "# meaningless. This is a must addition for this project.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)),\n",
    "                     dim_ordering='tf', # default\n",
    "                     input_shape=(160, 320, 3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    " \n",
    "model.fit(X_train, y_train, batch_size=32, validation_split=0.2, shuffle=True, nb_epoch=15)\n",
    "\n",
    "model.save('model-VGG_15_augmented-leftrightcam_personal_batch-32_split20.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified existing structure to add more depth to convolution layer, starting from 16 to 128, \n",
    "# to extract more features out of images\n",
    "\n",
    "# I also played with batch and validation split hyperparameters.\n",
    "\n",
    "# It didn't effect the results much after first try.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)),\n",
    "                     dim_ordering='tf', # default\n",
    "                     input_shape=(160, 320, 3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, validation_split=0.25, shuffle=True, nb_epoch=15)\n",
    "\n",
    "model.save('model-mod_VGG_15_augmented-leftrightcam_personal_batch-128_split25.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comm.ai structure tried couple times. Loss values not meaningful after couple epochs. \n",
    "# I have to work on this structure and make more trial and errors.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)),\n",
    "                     dim_ordering='tf', # default\n",
    "                     input_shape=(160, 320, 3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "\n",
    "model.add(Convolution2D(16, 8, 8, activation='relu'))\n",
    "model.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "model.add(Convolution2D(64, 5, 5, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, validation_split=0.20, shuffle=True, nb_epoch=15)\n",
    "\n",
    "model.save('model-Comm-ai_15_augmented-leftrightcam_personal_batch-128_split20.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
